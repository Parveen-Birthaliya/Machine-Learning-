{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e63365-3f60-4eaf-b250-b60d515386c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62318b3-6c4b-4819-888b-f2e4e92a5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b75dc75-0df3-4bea-9448-47da675ecd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d85a1a5-a77a-4956-ad85-c1bcf9f819b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchGD:\n",
    "    def __init__(self):\n",
    "        self.B0 = None\n",
    "        self.B = None\n",
    "\n",
    "    def fit(self, X_train, y_train,batch_size = 10, epochs = 100, lr = 0.1):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        # making a matrix of 1  for Beta (B)\n",
    "        # B = [B1, B2, ....Bn ]\n",
    "        self.B0 = 0\n",
    "        self.B = np.ones(X_train.shape[1])\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                \n",
    "                # Picking random sample of values from rows\n",
    "                idx = np.random.choice(range(X_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                # For the B0 (intercept) value\n",
    "                y_cap = np.dot(X_train[idx], self.B) + self.B0\n",
    "                der_B0 = -2 * np.mean(y_train[idx] - y_cap)\n",
    "                self.B0 = self.B0 - self.lr * der_B0\n",
    "\n",
    "                # For the coef_ values (B)\n",
    "                der_B = -2 * np.dot((y_train[idx] - y_cap) ,X_train[idx])\n",
    "                self.B = self.B - self.lr * der_B\n",
    "            print(self.B0,self.B)\n",
    "        print(\"Final B0 :\", self.B0)\n",
    "        print(\"Final B :\" ,self.B)\n",
    "    def pred(self,X_test):\n",
    "        return np.dot(X_test, self.B) + self.B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "175b06dc-a0b0-4e1b-bc53-fa7520375505",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbgd = MiniBatchGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90b615c3-37a6-4ea5-97f2-fc8ee705f067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.4796774115637 [  6.10925232  -2.21580026  80.4833258   53.93632972  36.51412097\n",
      "  24.40333949 -32.629978    44.30903284  74.06566149  35.42448664]\n",
      "155.73068441319887 [ 22.0492611   -4.29874903 133.15293306  99.97243104  36.69900053\n",
      "  18.02341442 -61.98276847  62.59911263 122.28385291  66.05651475]\n",
      "147.75926116095184 [ 27.59750925   1.32691794 185.38682539 134.58938776  36.66159188\n",
      "  14.30206977 -92.60715943  89.6020086  162.45679094  94.56974302]\n",
      "153.3359907466553 [  29.64780507   -9.81692415  231.55188733  157.52393673   39.57038217\n",
      "   11.88820622 -113.11484045  108.65734151  196.86509425  110.07924391]\n",
      "155.2566152590516 [  29.67359289  -11.87565452  257.6630614   175.004813     33.58434493\n",
      "    2.96375181 -134.90217098  124.48867861  222.92301354  116.60939197]\n",
      "159.27734555143422 [  37.09363462  -22.40086886  285.70900331  196.7901541    28.28834046\n",
      "   -6.6125811  -151.72274819  131.43713947  248.94814875  125.78034174]\n",
      "151.62656387341056 [  41.213439    -34.79291028  306.92296003  210.77158046   29.68242112\n",
      "   -9.34505954 -157.48581463  135.66796851  268.05061915  125.64038834]\n",
      "149.35719519960216 [  38.00934636  -44.63429339  327.75697453  227.21378062   25.82814068\n",
      "  -17.12531534 -167.63190457  142.68591039  290.10020259  132.13422744]\n",
      "150.57006494254506 [  34.47900696  -63.23427895  344.2943506   237.86141662   16.99585247\n",
      "  -28.47547432 -171.46452661  141.95679954  300.86608702  131.81085071]\n",
      "151.5159696190027 [  34.51839713  -67.59345229  361.1929553   250.41393217    9.24115592\n",
      "  -40.81553527 -179.71621062  143.23709317  319.02332708  140.26645983]\n",
      "157.47615289399766 [  29.69643901  -76.04079152  375.12650378  253.91718048    2.41874571\n",
      "  -51.79520925 -182.53131296  140.76346163  331.7624324   139.98624646]\n",
      "153.7810790362586 [  20.14590807  -87.66693727  390.27300241  263.51484064   -6.19049007\n",
      "  -64.43001689 -185.9046793   136.40335487  345.34775688  142.44348932]\n",
      "150.4977780452652 [  26.17359002 -101.5016336   404.9240199   274.78374879  -13.39411277\n",
      "  -76.7232438  -185.25693709  131.98019466  355.84105034  143.0209823 ]\n",
      "151.7680350187633 [  22.43392079 -112.25478633  412.40079051  274.28384071  -16.3251305\n",
      "  -81.02989005 -189.9365453   137.10056667  363.76975983  138.40143017]\n",
      "148.58271580589042 [  26.34917654 -121.11099744  421.13139556  282.3695352   -23.52712597\n",
      "  -91.81552182 -189.95653054  132.72648804  371.80895057  137.8054647 ]\n",
      "153.27263747940103 [  11.16986761 -140.73883823  439.53820758  279.09445761  -26.80371534\n",
      "  -95.41650853 -192.67718033  134.81955559  376.34462502  137.9131014 ]\n",
      "154.26907740010049 [   8.24871769 -149.74225858  447.75401268  292.1468198   -41.75651226\n",
      " -113.11489945 -191.57105252  125.28216711  381.18438319  140.01851192]\n",
      "152.22321811161277 [   8.35014881 -154.89714955  451.24994752  297.31322033  -41.24152105\n",
      " -113.96166599 -189.85711667  126.83442041  385.94227412  135.0505829 ]\n",
      "144.60130445949994 [   6.92654189 -160.8740596   460.69492173  296.79314355  -36.49647477\n",
      " -111.71149513 -190.64394018  131.71178798  394.77924894  134.073483  ]\n",
      "148.79376554184805 [   2.95749334 -169.66831372  469.05634023  300.51238983  -31.32769976\n",
      " -110.99701637 -189.25194039  133.71567068  407.66460128  134.91396071]\n",
      "153.64821936759978 [  11.03831027 -162.35398756  473.21546329  303.35189721  -36.00896049\n",
      " -114.85386845 -193.96767214  135.17018358  415.59292885  134.11220491]\n",
      "144.3464127001483 [   7.18629434 -161.55866638  471.03787884  303.65406264  -36.43296043\n",
      " -117.8197208  -195.33779438  136.90092084  422.62147472  139.02101296]\n",
      "151.27396521360905 [   1.76850516 -172.38109908  473.83938847  306.6304935   -41.33685192\n",
      " -121.81754983 -198.06269459  137.92607219  423.71069297  138.33765463]\n",
      "149.58727304030293 [   1.67883829 -182.81685712  483.59625586  309.90904198  -51.1155425\n",
      " -129.95375587 -204.8184788   138.82745338  427.1930327   131.88493816]\n",
      "147.40581400313167 [   3.30197924 -194.00128838  481.41567468  310.7807527   -54.27197329\n",
      " -137.43963561 -197.92670008  131.85341594  433.04003677  124.68308164]\n",
      "149.01769044237074 [   3.6800304  -193.17435789  485.39967915  310.08378594  -55.11884091\n",
      " -142.74171355 -190.9800806   123.62251958  436.34621394  123.04617428]\n",
      "157.2561489988603 [   7.82851208 -190.9978316   479.92812336  318.67126476  -52.49859472\n",
      " -136.18615435 -186.21117582  121.83496644  432.24309082  118.78803056]\n",
      "155.23672088555438 [   7.14882688 -192.77104504  485.75093486  320.26195634  -55.01770675\n",
      " -141.8602492  -180.44522544  117.22461027  433.36350636  111.05322362]\n",
      "157.84388883989644 [   9.0961413  -194.41271252  499.44872385  322.15714396  -56.20067373\n",
      " -141.13357078 -180.41153217  117.15803796  432.75633292  107.5172368 ]\n",
      "150.04924657845908 [   2.10398926 -196.28967592  509.45488419  319.51339216  -59.97636663\n",
      " -145.12082886 -183.29828571  120.07982237  436.81196575  101.04601155]\n",
      "146.168933379691 [   3.74936784 -203.86811159  513.29379123  324.37451885  -58.18860002\n",
      " -145.42713151 -179.62470311  120.41890536  441.44505111  107.22122359]\n",
      "148.43764966055372 [   4.35296779 -204.67277581  516.75200631  328.42964525  -57.20441087\n",
      " -147.70296024 -178.29107465  120.53991823  450.51146345  112.74789011]\n",
      "149.30475704366475 [   1.03244083 -201.64839939  517.13154428  330.67994247  -58.56838555\n",
      " -145.90662412 -181.46989477  119.23416275  449.7607413   110.53868703]\n",
      "148.04247685546883 [  -1.29263123 -204.77211433  517.09820199  329.34543115  -62.16837118\n",
      " -152.47377153 -180.43285579  117.98662852  457.97614673  110.41586501]\n",
      "151.11429564924805 [  -1.41236038 -202.02909469  521.34579283  332.57186837  -62.32382494\n",
      " -152.79021155 -185.97758383  122.72863332  467.97783564  108.38070966]\n",
      "153.41405516192083 [   1.07689628 -201.72234879  516.96170721  331.16758146  -61.85509715\n",
      " -152.38031521 -188.0733257   125.09204015  473.16181652  112.36632889]\n",
      "150.71395689034622 [  -1.3264435  -208.0680511   521.03065364  329.62443738  -63.9078641\n",
      " -154.75922706 -178.60269092  120.6587907   467.72471216  109.35746782]\n",
      "140.37253582562712 [  -3.56598689 -199.09953717  526.41362727  330.4842667   -68.59436563\n",
      " -160.6380564  -181.38634692  121.27904172  474.33816786  110.51037104]\n",
      "153.90993896869668 [  -7.20878554 -198.93736599  526.79708751  327.48010942  -61.36890453\n",
      " -152.04813246 -183.94950387  126.50215384  478.85073969  106.892253  ]\n",
      "150.90686521898627 [  -8.70639489 -196.19461889  528.61901717  328.77806075  -57.62338387\n",
      " -148.83422823 -184.38090752  127.74667345  484.1142805   108.34615899]\n",
      "Final B0 : 150.90686521898627\n",
      "Final B : [  -8.70639489 -196.19461889  528.61901717  328.77806075  -57.62338387\n",
      " -148.83422823 -184.38090752  127.74667345  484.1142805   108.34615899]\n"
     ]
    }
   ],
   "source": [
    "mbgd.fit(X_train,y_train,10,40,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6590109b-907f-4b4c-aee7-d1f01cc396b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mbgd.pred(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a279197-9e32-4197-824b-975382683e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49058395962787216"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8fe38-3c10-4f4c-af78-172834ad4ad6",
   "metadata": {},
   "source": [
    "# Improved version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d22fa0b-6ad1-4896-a5e6-7658fe841b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedMiniBatchGD:\n",
    "    def __init__(self):\n",
    "        self.B0 = None\n",
    "        self.B = None\n",
    "\n",
    "    def fit(self, X_train, y_train,batch_size = 10, epochs = 40, lr = 0.05):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        # making a matrix of 1  for Beta (B)\n",
    "        # B = [B1, B2, ....Bn ]\n",
    "        self.B0 = 0\n",
    "        self.B = np.ones(X_train.shape[1])\n",
    "\n",
    "        # Learning Schedule : varying learning rate\n",
    "        t0,t1 = 5,50\n",
    "        def learning_rate(t):\n",
    "            return t0/(t1+t)\n",
    "    \n",
    "        \n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                lr = learning_rate(i * X_train.shape[0] + j)\n",
    "                # Picking random sample of values from rows\n",
    "                idx = np.random.choice(range(X_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                # For the B0 (intercept) value\n",
    "                y_cap = np.dot(X_train[idx], self.B) + self.B0\n",
    "                der_B0 = -2 * np.mean(y_train[idx] - y_cap)\n",
    "                self.B0 = self.B0 - lr * der_B0\n",
    "\n",
    "                # For the coef_ values (B)\n",
    "                der_B = -2 * np.dot((y_train[idx] - y_cap) ,X_train[idx])/batch_size # taking mean\n",
    "                self.B = self.B - lr * der_B\n",
    "\n",
    "                # Track loss\n",
    "                loss = np.mean((y_train - (np.dot(X_train, self.B) + self.B0))**2)\n",
    "            print(\"loss:\", loss)\n",
    "            print(\" value B0:\" ,self.B0,\"value B:\",self.B)\n",
    "        print(\"Final B0 :\", self.B0)\n",
    "        print(\"Final B :\" ,self.B)\n",
    "    def pred(self,X_test):\n",
    "        return np.dot(X_test, self.B) + self.B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b535103-5e4c-4dd8-9c51-a84a308aed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedMiniBatchGD:\n",
    "    def __init__(self):\n",
    "        self.B0 = None\n",
    "        self.B = None\n",
    "\n",
    "    def fit(self, X_train, y_train,batch_size = 10, epochs = 40, lr = 0.05):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        # making a matrix of 1  for Beta (B)\n",
    "        # B = [B1, B2, ....Bn ]\n",
    "        self.B0 = 0\n",
    "        self.B = np.ones(X_train.shape[1])\n",
    "\n",
    "        # Learning Schedule : varying learning rate\n",
    "        t0,t1 = 5,100\n",
    "        def learning_rate(t):\n",
    "            return t0/(t1+t)\n",
    "    \n",
    "        \n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                lr = learning_rate(i * X_train.shape[0] + j)\n",
    "                # Picking random sample of values from rows\n",
    "                idx = np.random.choice(range(X_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                # For the B0 (intercept) value\n",
    "                y_cap = np.dot(X_train[idx], self.B) + self.B0\n",
    "                der_B0 = -2 * np.mean(y_train[idx] - y_cap)\n",
    "                self.B0 = self.B0 - lr * der_B0\n",
    "\n",
    "                # For the coef_ values (B)\n",
    "                der_B = -2 * np.dot((y_train[idx] - y_cap) ,X_train[idx])/batch_size # taking mean\n",
    "                self.B = self.B - lr * der_B\n",
    "\n",
    "                # Track loss\n",
    "                loss = np.mean((y_train - (np.dot(X_train, self.B) + self.B0))**2)\n",
    "            print(\"loss:\", loss)\n",
    "            print(\" value B0:\" ,self.B0,\"value B:\",self.B)\n",
    "        print(\"Final B0 :\", self.B0)\n",
    "        print(\"Final B :\" ,self.B)\n",
    "    def pred(self,X_test):\n",
    "        return np.dot(X_test, self.B) + self.B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64eee72b-4031-4512-aeda-db34b2c92cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbgd = ImprovedMiniBatchGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1db6a6e7-8a2a-4269-b23c-da7fbef6efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5956.879996735325\n",
      " value B0: 153.76263766940974 value B: [ 1.87879139  2.32498301  9.59677074  7.58124758  2.55677419  1.26927942\n",
      " -3.85795061  5.56801276  9.16407688  6.46583369]\n",
      "loss: 5947.3466016328775\n",
      " value B0: 156.16459315556034 value B: [ 1.91449484  2.29771242 11.34174475  8.7350779   2.84148836  1.49814858\n",
      " -4.79393019  6.46418431 10.41077754  7.20970116]\n",
      "loss: 5926.198162367441\n",
      " value B0: 155.6626504365532 value B: [ 2.26526913  2.42109688 12.31965111  9.57868627  3.10707029  1.70036559\n",
      " -5.4366332   7.12893758 11.32420706  7.78829936]\n",
      "loss: 5903.105523698665\n",
      " value B0: 153.5417496504138 value B: [ 2.45677654  2.63969938 12.93535256 10.0683302   3.24413578  1.77345413\n",
      " -5.89769835  7.60906886 11.98863661  8.24538073]\n",
      "loss: 5893.361457539819\n",
      " value B0: 152.8028841714092 value B: [ 2.61975335  2.65276162 13.39781548 10.40093472  3.4196417   1.9016522\n",
      " -6.13238017  7.91279159 12.41593256  8.57332218]\n",
      "loss: 5886.24964865675\n",
      " value B0: 152.84489381716273 value B: [ 2.73342626  2.65968825 13.80093552 10.72181153  3.57841781  2.02709433\n",
      " -6.39479153  8.20562552 12.82537734  8.82986738]\n",
      "loss: 5880.271503744427\n",
      " value B0: 152.07367312095727 value B: [ 2.81038536  2.6784364  14.15478556 10.92875703  3.64595644  2.06132155\n",
      " -6.57085293  8.37633343 13.12709561  8.98805951]\n",
      "loss: 5875.100375025571\n",
      " value B0: 151.61514735935714 value B: [ 2.89697331  2.74462481 14.42284287 11.19490167  3.74911431  2.13461722\n",
      " -6.75111206  8.57355691 13.41165901  9.21032951]\n",
      "loss: 5870.7419899289025\n",
      " value B0: 152.3945864338693 value B: [ 2.96053454  2.77227729 14.68410563 11.40609402  3.8320695   2.20578298\n",
      " -6.92899218  8.77635728 13.66705716  9.35813863]\n",
      "loss: 5866.931994502634\n",
      " value B0: 151.75176981131492 value B: [ 3.01387314  2.798361   14.86958834 11.55485919  3.86257074  2.22697418\n",
      " -7.10509632  8.92560435 13.87934659  9.48440516]\n",
      "loss: 5863.130937578702\n",
      " value B0: 151.37052295828582 value B: [ 3.11186275  2.87569631 15.10901229 11.74041064  3.93218813  2.28201375\n",
      " -7.25065122  9.08224038 14.09136983  9.62841408]\n",
      "loss: 5860.421056249383\n",
      " value B0: 151.3084615415384 value B: [ 3.14631653  2.87515721 15.27269775 11.85948051  3.9928209   2.32970387\n",
      " -7.35269197  9.19265704 14.24964507  9.73251113]\n",
      "loss: 5858.200445453016\n",
      " value B0: 151.0833226092603 value B: [ 3.18708674  2.91202494 15.43167115 11.96885897  4.02137579  2.36083291\n",
      " -7.45414763  9.29493751 14.37607461  9.83099662]\n",
      "loss: 5856.241579928643\n",
      " value B0: 150.8794579406434 value B: [ 3.21915475  2.91679883 15.57541907 12.08835665  4.05980841  2.37746778\n",
      " -7.52430494  9.3759619  14.5191921   9.90522588]\n",
      "loss: 5854.037183225473\n",
      " value B0: 150.72964454261538 value B: [ 3.27366059  2.93967619 15.72809984 12.1962161   4.12262919  2.42071848\n",
      " -7.59822643  9.47413196 14.65778127 10.00583197]\n",
      "loss: 5851.9894175971185\n",
      " value B0: 150.69868335974306 value B: [ 3.29922455  2.94215017 15.84514381 12.28182246  4.17131719  2.4613803\n",
      " -7.67562496  9.57024962 14.78082223 10.08751899]\n",
      "loss: 5849.737042887621\n",
      " value B0: 150.86596550868524 value B: [ 3.32231637  2.95194771 15.95317504 12.37341387  4.19770059  2.47764755\n",
      " -7.749795    9.64198424 14.891486   10.16107292]\n",
      "loss: 5847.575324888894\n",
      " value B0: 150.97079030093286 value B: [ 3.35747402  2.95225811 16.07697855 12.45027843  4.21813367  2.4873953\n",
      " -7.8359545   9.72502205 15.00836115 10.22162906]\n",
      "loss: 5845.383326876826\n",
      " value B0: 151.1111099667488 value B: [ 3.39185414  2.97447847 16.19914492 12.54685535  4.25437238  2.51823645\n",
      " -7.91296989  9.79850211 15.11161777 10.28260805]\n",
      "loss: 5843.558954956878\n",
      " value B0: 151.09655042630314 value B: [ 3.41706983  2.99836709 16.31076396 12.64287246  4.27584276  2.53440808\n",
      " -7.98623443  9.86461668 15.21147027 10.35066475]\n",
      "loss: 5841.53193411017\n",
      " value B0: 151.33417514846354 value B: [ 3.44287937  3.00184199 16.41194151 12.72758373  4.30057532  2.55271211\n",
      " -8.05187945  9.93329458 15.30349476 10.42121792]\n",
      "loss: 5839.4723902826245\n",
      " value B0: 151.47389222227406 value B: [ 3.47332088  3.01972107 16.52026196 12.81376252  4.34838726  2.58762538\n",
      " -8.12101838 10.01481846 15.4156891  10.48791042]\n",
      "loss: 5837.951359471226\n",
      " value B0: 151.57956010322675 value B: [ 3.50029891  3.02942213 16.59935443 12.8739886   4.36511586  2.59874181\n",
      " -8.18470522 10.07564852 15.50322309 10.54415511]\n",
      "loss: 5836.489402512874\n",
      " value B0: 151.5214713046967 value B: [ 3.54147483  3.04293983 16.69163958 12.94683907  4.38166734  2.61083436\n",
      " -8.24539073 10.13107499 15.58426489 10.59203406]\n",
      "loss: 5834.841258246864\n",
      " value B0: 151.69860232081965 value B: [ 3.56574072  3.05884296 16.79880074 13.00892163  4.38537909  2.61146476\n",
      " -8.31662212 10.19645216 15.66730692 10.64765363]\n",
      "loss: 5833.393376780574\n",
      " value B0: 151.74636110781748 value B: [ 3.60072202  3.07126637 16.88319006 13.08170462  4.40873106  2.63255675\n",
      " -8.37395856 10.25445093 15.73932027 10.69642108]\n",
      "loss: 5832.11845270351\n",
      " value B0: 151.69676827904934 value B: [ 3.63299271  3.07132258 16.95489648 13.14382644  4.42550013  2.64412735\n",
      " -8.42429482 10.30241819 15.80945645 10.75375234]\n",
      "loss: 5831.186181174922\n",
      " value B0: 151.35834839583958 value B: [ 3.65473243  3.07901927 17.01839873 13.19759978  4.44460427  2.65811978\n",
      " -8.47062739 10.35170516 15.87411094 10.79527429]\n",
      "loss: 5829.842473414319\n",
      " value B0: 151.50768444528737 value B: [ 3.67275594  3.08667112 17.08188077 13.25124846  4.46631796  2.67528568\n",
      " -8.52296149 10.40709006 15.94570603 10.83912   ]\n",
      "loss: 5828.776324190861\n",
      " value B0: 151.30745461370503 value B: [ 3.69604737  3.09400636 17.14714741 13.30615937  4.49626849  2.69660951\n",
      " -8.56517219 10.45847215 16.01632431 10.89602169]\n",
      "loss: 5827.693260205417\n",
      " value B0: 151.17491165003236 value B: [ 3.71538937  3.10459005 17.21201436 13.36541791  4.5223544   2.71555608\n",
      " -8.61203547 10.51009295 16.08913229 10.94447492]\n",
      "loss: 5826.511999829551\n",
      " value B0: 151.22547104254946 value B: [ 3.7308509   3.11566864 17.28440822 13.41641409  4.53468641  2.72232161\n",
      " -8.65569593 10.55372914 16.15113626 10.98375888]\n",
      "loss: 5825.651059186129\n",
      " value B0: 151.07304376787533 value B: [ 3.75514666  3.12474788 17.34862353 13.47357898  4.54877007  2.73240603\n",
      " -8.69563155 10.59236093 16.21166002 11.0186466 ]\n",
      "loss: 5824.538300050404\n",
      " value B0: 151.07253162504108 value B: [ 3.7687492   3.13588614 17.41503123 13.52403686  4.56474384  2.74154432\n",
      " -8.74093909 10.63688141 16.27589718 11.05976478]\n",
      "loss: 5823.655075801108\n",
      " value B0: 151.05320106729602 value B: [ 3.77528625  3.13625485 17.46711073 13.5643262   4.58555113  2.75835062\n",
      " -8.77466691 10.67690455 16.3273959  11.09673449]\n",
      "loss: 5822.534712555739\n",
      " value B0: 151.1032785926905 value B: [ 3.79171804  3.14697635 17.52541727 13.60473124  4.60473365  2.77322985\n",
      " -8.81632043 10.72360497 16.38808442 11.1386043 ]\n",
      "loss: 5821.75182077013\n",
      " value B0: 151.00856020169996 value B: [ 3.81728129  3.15519698 17.57652488 13.64674756  4.61730046  2.7798712\n",
      " -8.85430748 10.75787448 16.44735832 11.17015827]\n",
      "loss: 5820.8012360071425\n",
      " value B0: 151.0637987864878 value B: [ 3.83378737  3.15971192 17.6299082  13.69477893  4.62616578  2.78795774\n",
      " -8.88740758 10.78844938 16.49206939 11.20079085]\n",
      "loss: 5819.748494332511\n",
      " value B0: 151.15596449808734 value B: [ 3.8460353   3.1611124  17.68363728 13.73584794  4.63623334  2.79038793\n",
      " -8.92273758 10.82351106 16.54999012 11.2372508 ]\n",
      "loss: 5818.785306835583\n",
      " value B0: 151.18086366274264 value B: [ 3.86218114  3.16878781 17.73931947 13.77555822  4.64758707  2.79502319\n",
      " -8.96041726 10.86086696 16.60558766 11.27149179]\n",
      "Final B0 : 151.18086366274264\n",
      "Final B : [ 3.86218114  3.16878781 17.73931947 13.77555822  4.64758707  2.79502319\n",
      " -8.96041726 10.86086696 16.60558766 11.27149179]\n"
     ]
    }
   ],
   "source": [
    "imbgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15137d81-fbf9-40a5-b53f-82399b94814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = imbgd.pred(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8afad22-7c3e-46fa-a247-686470c911ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050476431727202065"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf226fa-3b70-4c67-a435-0d4284b01bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effda4e-df8b-4c3e-8264-76e078fbdb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7758637-102e-4608-8a08-e804a6c5bf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
